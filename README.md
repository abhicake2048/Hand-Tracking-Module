
# Hand Tracking module

This project provides a hand tracking module using MediaPipe, a popular open-source framework developed by Google for building machine learning-based pipelines for various perception tasks. The module allows for real-time hand tracking and gesture recognition from webcam or video input, enabling applications such as virtual touchless interfaces, sign language recognition, and interactive experiences.
## Features

- Real-time Hand Tracking : The module uses MediaPipe's pre-trained hand tracking model to detect and track hand landmarks in real-time.
- Robustness and Accuracy : The hand tracking model achieves high accuracy and robustness across various lighting conditions, hand poses, and backgrounds.
- Easy Integration : The module is designed to be easily integrated into existing Python projects, providing a simple API for accessing hand tracking functionality.
- Customization : Users can customize the module to suit their specific requirements, such as adjusting tracking parameters, defining custom gestures, or integrating with other computer vision algorithms.

## Requirements

- Python
- Mediapipe
- Numpy
- OpenCV


## Installation

- Clone this repository to your local machine.
- Install the required dependencies using pip install -r requirements.txt.
- Optionally, download additional MediaPipe models or assets if required for specific functionality.
    
## Usage

- Import the HandTrackingModule class from the module.
- Create an instance of the HandTrackingModule.
- Initialize the hand tracking module.
- Provide webcam or video input to the module for real-time hand tracking.
- Access detected hand landmarks and perform gesture recognition as needed.
- Integrate the module with your application logic to enable interactive hand tracking features.
## Screenshots

![Video used for Prediction](https://drive.google.com/file/d/1FjgYKJEZUxG1ClmtOLg5b6xCuVx5mpQt/view?usp=drive_link)

![Output](https://drive.google.com/file/d/1otKOEqF46lGDkhD_wT8gOmV-iy6mZa29/view?usp=drive_link)

